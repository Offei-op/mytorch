{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d21af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b748f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a6449a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a2ecd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emma'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e1c21b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = sorted(list(set(''.join(words))))\n",
    "stoi ={s:i+1 for i,s in enumerate(alphabets)}\n",
    "stoi[\".\"] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5781af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27,27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c6b3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting\n",
    "\n",
    "for w in words:\n",
    "    ch = \".\" + w + \".\"\n",
    "    for chr1,chr2 in zip(ch,ch[1:]):\n",
    "        ix1 = stoi[chr1]\n",
    "        ix2 = stoi[chr2]\n",
    "        N[ix1,ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "251959c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create probability distribution\n",
    "P = N / N.sum(1,keepdim=True)\n",
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0586e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zasesabll.\n"
     ]
    }
   ],
   "source": [
    "# Sample\n",
    "\n",
    "word = \"\"\n",
    "ch = \".\"\n",
    "while True:\n",
    "    \n",
    "    ix = stoi[ch]\n",
    "    word += itos[torch.multinomial(P[ix],num_samples=1).item()]\n",
    "    ch = word[-1]\n",
    "    if ch == \".\":\n",
    "        break    \n",
    "print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa97144",
   "metadata": {},
   "source": [
    "Tri-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee34d861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(string_pairs) = 729\n",
      "string_pairs[0] = 'aa'\n",
      "string_pairs[1] = 'ab'\n"
     ]
    }
   ],
   "source": [
    "string_pairs = [a+b for a in stoi.keys() for b in stoi.keys()]\n",
    "print(f\"{len(string_pairs) = }\")\n",
    "print(f\"{string_pairs[0] = }\")\n",
    "print(f\"{string_pairs[1] = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af213929",
   "metadata": {},
   "outputs": [],
   "source": [
    "sptoi = {s:i for i,s in enumerate(string_pairs)}\n",
    "itosp = {i:s for s,i in sptoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "955c44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_N = torch.zeros((729,27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dad4409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting trigrams\n",
    "\n",
    "for w in words:\n",
    "    ch = \"..\" + w + \".\"\n",
    "    for chr1,chr2,chr3 in zip(ch,ch[1:],ch[2:]):\n",
    "        ix1 = sptoi[chr1+chr2]\n",
    "        ix2 = stoi[chr3]\n",
    "        tri_N[ix1,ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06627e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40.)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_N[sptoi[\"aa\"],stoi[\".\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b4d78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create probability distribution\n",
    "tri_P = tri_N / tri_N.sum(1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0950ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..re.\n"
     ]
    }
   ],
   "source": [
    "# Sample\n",
    "\n",
    "word = \"..\"\n",
    "ch = \"..\"\n",
    "while True:\n",
    "    ix = sptoi[ch]\n",
    "    word += itos[torch.multinomial(tri_P[ix],num_samples=1).item()]\n",
    "    ch = word[-2:]\n",
    "    if word[-1] == \".\":\n",
    "        break    \n",
    "print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2caf1e9",
   "metadata": {},
   "source": [
    "Calculating loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75c1dca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nll=tensor(559891.7500)\n",
      "nll/n=tensor(2.4541)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "likelihood = 0\n",
    "n =0 \n",
    "for w in words:\n",
    "    ch = \".\" + w +\".\"\n",
    "    for chr1,chr2 in zip(ch,ch[1:]):\n",
    "        ix1 = stoi[chr1]\n",
    "        ix2 = stoi[chr2]\n",
    "        likelihood += torch.log(P[ix1,ix2])\n",
    "        n += 1\n",
    "        nll = -likelihood\n",
    "\n",
    "print(f\"{nll=}\")\n",
    "print(f\"{nll/n=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4210616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tri_nll=tensor(498647.7812)\n",
      "tri_nll/n=tensor(2.1857)\n"
     ]
    }
   ],
   "source": [
    "trigram_likelihood = 0\n",
    "n = 0\n",
    "\n",
    "for w in words:\n",
    "    ch = \"..\" + w +\".\"\n",
    "    for chr1,chr2,chr3 in zip(ch,ch[1:],ch[2:]):\n",
    "        ix1 = sptoi[chr1 + chr2]\n",
    "        ix2 = stoi[chr3]\n",
    "        trigram_likelihood += torch.log(tri_P[ix1,ix2])\n",
    "        n += 1\n",
    "        tri_nll = -trigram_likelihood\n",
    "\n",
    "print(f\"{tri_nll=}\")\n",
    "print(f\"{tri_nll/n=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffb03347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a -> a.\n",
      "b -> bri.\n",
      "c -> ca.\n",
      "d -> da.\n",
      "e -> e.\n",
      "f -> fa.\n",
      "g -> gh.\n",
      "h -> h.\n",
      "i -> i.\n",
      "j -> ja.\n",
      "k -> ka.\n",
      "l -> le.\n",
      "m -> ma.\n",
      "n -> n.\n",
      "o -> on.\n",
      "p -> pa.\n",
      "q -> qush.\n",
      "r -> ri.\n",
      "s -> sh.\n",
      "t -> ta.\n",
      "u -> ush.\n",
      "v -> vi.\n",
      "w -> wa.\n",
      "x -> x.\n",
      "y -> ya.\n",
      "z -> za.\n"
     ]
    }
   ],
   "source": [
    "#Generating the most likely name according to bigram and trigram models\n",
    "\n",
    "for al in alphabets:\n",
    "    ch = al\n",
    "    word = ch\n",
    "    while True:\n",
    "        \n",
    "        ix = stoi[ch]\n",
    "        word += itos[torch.argmax(P[ix]).item()]\n",
    "        ch = word[-1]\n",
    "        if ch == \".\":\n",
    "            break    \n",
    "\n",
    "    print(al,\"->\",word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f77e1f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "xs = []\n",
    "ys = []\n",
    "for w in words:\n",
    "    ch = \".\" + w + \".\"\n",
    "    for chr1,chr2 in zip(ch,ch[1:]):\n",
    "        ix1 = stoi[chr1]\n",
    "        ix2 = stoi[chr2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46a913b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((27,27),requires_grad=True)\n",
    "x_enc = F.one_hot(xs,num_classes=27)\n",
    "x_enc = x_enc.T.float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37153642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8105, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = (W @ x_enc).exp()\n",
    "probs = counts/counts.sum(dim=0,keepdim=True)\n",
    "logits = probs[ys,torch.arange(0,len(ys))]\n",
    "loss = -logits.log().mean()\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba7178a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8105, grad_fn=<NegBackward0>)\n",
      "tensor(2.6702, grad_fn=<NegBackward0>)\n",
      "tensor(2.5658, grad_fn=<NegBackward0>)\n",
      "tensor(2.5278, grad_fn=<NegBackward0>)\n",
      "tensor(2.5086, grad_fn=<NegBackward0>)\n",
      "tensor(2.4969, grad_fn=<NegBackward0>)\n",
      "tensor(2.4891, grad_fn=<NegBackward0>)\n",
      "tensor(2.4835, grad_fn=<NegBackward0>)\n",
      "tensor(2.4793, grad_fn=<NegBackward0>)\n",
      "tensor(2.4760, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Training cycle\n",
    "\n",
    "for i in range(500):\n",
    "    counts = (W @ x_enc).exp()\n",
    "    probs = counts/counts.sum(dim=0,keepdim=True)\n",
    "    logits = probs[ys,torch.arange(0,len(ys))]\n",
    "    loss = -logits.log().mean()\n",
    "\n",
    "    W.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    W.data -= 10 * W.grad\n",
    "    if i%50 == 0:\n",
    "        print(loss)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0becc5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ry\n"
     ]
    }
   ],
   "source": [
    "#Sampling\n",
    "ch = \".\"\n",
    "word = \"\"\n",
    "while True:\n",
    "    \n",
    "    x = F.one_hot(torch.tensor(stoi[ch]),num_classes=27).float()\n",
    "    x = torch.reshape(x,(-1,1))\n",
    "    N = (W @ x).exp()\n",
    "    probs = N/N.sum(dim=0,keepdim=True)\n",
    "    probs = probs.T\n",
    "    pred = torch.multinomial(probs,num_samples=1)\n",
    "    next_ch = itos[pred.item()]\n",
    "    ch = next_ch\n",
    "   \n",
    "\n",
    "    if next_ch == \".\":\n",
    "        break\n",
    "    word += next_ch\n",
    "\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ae9a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "for w in words:\n",
    "    ch = \".\" + w + \".\"\n",
    "    for chr1,chr2 in zip(ch,ch[1:]):\n",
    "        ix1 = stoi[chr1]\n",
    "        ix2 = stoi[chr2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1da1d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((27,27),requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "49493627",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    counts = (W @ x_enc).exp()\n",
    "    probs = counts/counts.sum(dim=0,keepdim=True)\n",
    "    logits = probs[ys,torch.arange(0,len(ys))]\n",
    "    loss = -logits.log().mean()\n",
    "\n",
    "    W.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    W.data -= 10 * W.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7b013333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0616, grad_fn=<SqrtBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = (W @ x_enc).exp()\n",
    "probs = counts/counts.sum(dim=0,keepdim=True)\n",
    "true_probs = P[ys].T\n",
    "\n",
    "mse_loss = ((probs - true_probs)**2).mean()\n",
    "rmse_loss = torch.sqrt(mse_loss)\n",
    "rmse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a79862ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((27,27),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "86261704",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    counts = (W @ x_enc).exp()\n",
    "    probs = counts/counts.sum(dim=0,keepdim=True)\n",
    "    true_probs = P[ys].T\n",
    "\n",
    "    mse_loss = ((probs - true_probs)**2).mean()\n",
    "    rmse_loss = torch.sqrt(mse_loss)\n",
    "    rmse_loss\n",
    "\n",
    "    W.grad = None\n",
    "\n",
    "    rmse_loss.backward()\n",
    "\n",
    "    W.data -= 1000 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4c64cd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.2226, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = (W @ x_enc).exp()\n",
    "probs = counts/counts.sum(dim=0,keepdim=True)\n",
    "logits = probs[ys,torch.arange(0,len(ys))]\n",
    "loss = -logits.log().mean()\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
